/**
 * Sitemap Service - Generate and validate XML sitemaps
 */
import axios from 'axios';
import * as cheerio from 'cheerio';
import { readFileSync, writeFileSync } from 'fs';
import ora from 'ora';
import { URL } from 'url';
// @ts-ignore - No types available for xml2js
import { parseStringPromise } from 'xml2js';
import xmlbuilder from 'xmlbuilder';

const visited = new Set<string>();

interface UrlWithDepth {
  url: string;
  depth: number;
}

/**
 * Fetch and parse HTML page to extract links
 */
const fetchAndParse = async (url: string, website: string, spinner: any): Promise<string[]> => {
  try {
    const { data } = await axios.get(url);
    const $ = cheerio.load(data);
    const links: string[] = [];

    $('a').each((_: any, element: any) => {
      const href = $(element).attr('href');
      if (href) {
        const absoluteUrl = new URL(href, url).href;

        if (absoluteUrl.startsWith(website) && !visited.has(absoluteUrl)) {
          links.push(absoluteUrl);
        }
      }
    });

    spinner.text = `Total links found ${visited.size}, Found ${links.length} new links on ${url}`;
    return links;
  } catch (error) {
    spinner.fail(`Error fetching ${url}: ${(error as Error).message}`);
    return [];
  }
};

/**
 * Build XML sitemap from crawled URLs
 */
const buildSitemap = (urls: UrlWithDepth[], maxDepth: number, changefreq: string, website: string, replacer: string): string => {
  const root = xmlbuilder
    .create('urlset', { version: '1.0', encoding: 'UTF-8' })
    .att('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')
    .att('xmlns:xsi', 'http://www.w3.org/2001/XMLSchema-instance')
    .att('xsi:schemaLocation', 'http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd');

  root.com('Generated by SEO Master, Know more about @nayan-ui/cli @ https://www.nayanui.com/cli');

  urls.forEach(({ url, depth }) => {
    const priority = (maxDepth - depth) / maxDepth;
    const finalUrl = replacer ? url.replace(website, replacer) : url;

    root.ele('url').ele('loc', finalUrl).up().ele('changefreq', changefreq).up().ele('priority', priority.toFixed(1)).up();
  });

  return root.end({ pretty: true });
};

/**
 * Crawl website and generate XML sitemap
 * @param website - Base URL to crawl
 * @param replacer - URL to replace in final sitemap
 * @param maxDepth - Maximum crawl depth
 * @param output - Output file path
 * @param changefreq - Change frequency for URLs
 */
export const generateSitemap = async (website: string, replacer: string, maxDepth: number, output: string, changefreq: string): Promise<void> => {
  const spinner = ora(`Crawling website: ${website}`).start();

  const queue: UrlWithDepth[] = [{ url: website, depth: 0 }];
  visited.add(website);

  while (queue.length > 0) {
    const { url, depth } = queue.shift()!;

    if (depth < maxDepth) {
      const links = await fetchAndParse(url, website, spinner);

      for (const link of links) {
        if (!visited.has(link)) {
          visited.add(link);
          queue.push({ url: link, depth: depth + 1 });
        }
      }
    }
  }

  const urlsWithDepth = Array.from(visited).map(url => ({
    url,
    depth: url.split('/').length - website.split('/').length
  }));

  const sitemapXml = buildSitemap(urlsWithDepth, maxDepth, changefreq, website, replacer);
  writeFileSync(output, sitemapXml);

  spinner.succeed(`Sitemap saved to ${output}`);
};

/**
 * Validate XML sitemap format and structure
 * @param sitemapPath - Path or URL to sitemap
 * @param isRemote - Whether the sitemap is hosted remotely
 */
export const validateSitemap = async (sitemapPath: string, isRemote: boolean): Promise<{ status: boolean; message: string }> => {
  const spinner = ora(`Validating sitemap: ${sitemapPath}`).start();

  try {
    const sitemapContent = isRemote ? (await axios.get(sitemapPath)).data : readFileSync(sitemapPath, 'utf-8');
    const result = await parseStringPromise(sitemapContent);

    if (!result.urlset || !Array.isArray(result.urlset.url)) {
      throw new Error('Invalid sitemap: Root element must be <urlset>.');
    }

    const validChangefreq = ['always', 'hourly', 'daily', 'weekly', 'monthly', 'yearly', 'never'];

    result.urlset.url.forEach((entry: any, index: number) => {
      spinner.text = `Validating ${index + 1}/${result.urlset.url.length} URLs`;

      if (!entry.loc || !entry.loc[0]) {
        throw new Error('Invalid sitemap: Each <url> must contain a <loc> element.');
      }

      try {
        new URL(entry.loc[0]);
      } catch {
        throw new Error(`Invalid URL format: ${entry.loc[0]}`);
      }

      if (entry.changefreq && !validChangefreq.includes(entry.changefreq[0])) {
        throw new Error(`Invalid <changefreq> value: ${entry.changefreq[0]}`);
      }

      if (entry.priority && (isNaN(entry.priority[0]) || entry.priority[0] < 0 || entry.priority[0] > 1)) {
        throw new Error(`Invalid <priority> value: ${entry.priority[0]}`);
      }
    });

    const message = `Sitemap is valid with ${result.urlset.url.length} URLs`;
    spinner.succeed(message);
    return { status: true, message };
  } catch (error: any) {
    const message = `Sitemap validation error: ${error.message}`;
    spinner.fail(message);
    return { status: false, message };
  }
};
